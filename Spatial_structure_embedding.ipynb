{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct graph from SVIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from PIL import Image\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "\n",
    "\n",
    "# load Mask2Former fine-tuned on Cityscapes semantic segmentation\n",
    "# feature_extractor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
    "# model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\").cuda()\n",
    "\n",
    "# # 加载模型\n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\").cuda()\n",
    "model.eval()\n",
    "\n",
    "# Get list of class names as column names\n",
    "class_names = list(model.config.id2label.values())[1:]\n",
    "\n",
    "# 定义一个函数，用来计算bounding box\n",
    "def get_bounding_box(nodes):\n",
    "    min_i, min_j = nodes.min(axis=0)\n",
    "    max_i, max_j = nodes.max(axis=0)\n",
    "    return (min_j, min_i, max_j+1, max_i+1)\n",
    "\n",
    "def get_mask(image):\n",
    "    inputs = feature_extractor(image, return_tensors=\"pt\").to(model.device)\n",
    "    # 对输入图片进行分割\n",
    "    with torch.no_grad():    \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy().squeeze().astype('uint8')  # shape (batch_size, height/4, width/4)\n",
    "    return predictions\n",
    "\n",
    "def get_graph(predictions):\n",
    "    \n",
    "    mask = predictions\n",
    "    labels = list(np.unique(predictions))\n",
    "\n",
    "    # 创建空的图\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # 添加节点\n",
    "    for label in labels:\n",
    "        nodes = np.argwhere(mask == label)  # 获取当前标签对应的像素点坐标\n",
    "        centroid = np.mean(nodes, axis=0)   # 计算节点的中心坐标\n",
    "        count = len(nodes)                  # 获取节点的像素点数目\n",
    "        total_count = mask.size             # 获取整张图的像素点数目\n",
    "        proportion = count / total_count*100   # 计算节点所占比例\n",
    "        G.add_node(label, centroid=centroid, label=class_names[label-1], proportion=proportion)  # 添加节点，并记录节点的中心坐标和节点所占比例\n",
    "    \n",
    "    # 添加边\n",
    "    for i, (label_i, data_i) in enumerate(G.nodes(data=True)):\n",
    "        for j, (label_j, data_j) in enumerate(G.nodes(data=True)):\n",
    "            if i >= j:  # 避免重复添加边\n",
    "                continue\n",
    "            dist = np.linalg.norm(data_i['centroid'] - data_j['centroid'])  # 计算节点之间的欧式距离\n",
    "            if dist < 42:  # 如果两个节点之间的距离小于一个阈值，则添加一条边\n",
    "                G.add_edge(label_i, label_j)\n",
    "\n",
    "    # 将节点的比例作为特征嵌入图中\n",
    "    node_features = np.array([data['proportion'] for _, data in G.nodes(data=True)])\n",
    "\n",
    "    return node_features,G\n",
    "\n",
    "def get_embedding(node_features, G):\n",
    "    \n",
    "    # 定义嵌入层将特征从 1 维映射到 5 维\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "    x = nn.Embedding(len(x), 5)(torch.arange(len(x)).long())  # 15 表示节点数，5 表示嵌入后的特征维度\n",
    "\n",
    "    edge_index = from_networkx(G).edge_index\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index,)\n",
    "\n",
    "    # 定义 GCN 模型\n",
    "    class GCN(torch.nn.Module):\n",
    "        def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "            super(GCN, self).__init__()\n",
    "            self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "            self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = F.relu(self.conv1(x, edge_index))\n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = torch.mean(x, dim=0)  # 将所有节点的特征求平均得到图的嵌入向量\n",
    "            x = torch.nn.Linear(x.shape[0], 5)(x)  # 将嵌入向量映射为 5 维向量\n",
    "            return x\n",
    "\n",
    "    # 初始化 GCN 模型并传入数据进行计算\n",
    "    model = GCN(in_channels=5, hidden_channels=16, out_channels=5)\n",
    "    embedding = model(data.x, data.edge_index)\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 定义要处理的文件夹路径\n",
    "folder_path = \"E:/Dataset/GNN_Perception/wuhan_badu_SVI/baidu2023_pinjie/\"\n",
    "\n",
    "# 定义输出CSV文件路径\n",
    "output_file_path = \"E:/Dataset/GNN_Perception/wuhan_badu_SVI/2023/embedding.csv\"\n",
    "\n",
    "# 遍历文件夹中的所有文件\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # 读取图像\n",
    "        image = Image.open(os.path.join(folder_path, filename))\n",
    "        (node_features,G) = get_graph(get_mask(image))\n",
    "        embedding = get_embedding(node_features,G)\n",
    "\n",
    "        # 将处理后的数据存储到CSV文件中\n",
    "        with open(output_file_path, mode='a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            row = [filename, embedding]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## big graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##获取同一类别街景的边，构建实体大图\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_edge(predictions):\n",
    "    \n",
    "    labels = list(np.unique(predictions))\n",
    "\n",
    "    # 创建空的列表存储节点坐标\n",
    "    nodes = []\n",
    "\n",
    "    # 添加节点\n",
    "    for label in labels:\n",
    "        indices = np.argwhere(predictions == label)  # 获取当前标签对应的像素点坐标\n",
    "        centroid = np.mean(indices, axis=0)   # 计算节点的中心坐标\n",
    "        nodes.append((label-1, centroid))\n",
    "    \n",
    "    e= []\n",
    "    # 添加边\n",
    "    for i, (label_i, centroid_i) in enumerate(nodes):\n",
    "        for j, (label_j, centroid_j) in enumerate(nodes):\n",
    "            if i >= j:  # 避免重复添加边\n",
    "                continue\n",
    "            dist = np.linalg.norm(centroid_i - centroid_j)  # 计算节点之间的欧式距离\n",
    "            \n",
    "            if dist < 42:  # 如果两个节点之间的距离小于一个阈值，则添加一条边\n",
    "                e.append([label_i, label_j])\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 读取CSV文件并获取所有id值\n",
    "with open('E:/Dataset/GNN_Perception/fig_out/pre2.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    id_list = [row[1] for row in reader]\n",
    "    \n",
    "new_id_list = [x.split('_')[0] for x in id_list]\n",
    "new_id_list\n",
    "\n",
    "# 定义要处理的文件夹路径\n",
    "folder_path = \"E:/Dataset/GNN_Perception/wuhan_badu_SVI/baidu2023_pinjie\"\n",
    "# folder_path = \"E:/Dataset/GNN_Perception/wuhan_badu_SVI/baidu2022\"\n",
    "\n",
    "data=[]\n",
    "# 遍历文件夹中的所有图片\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    # 解析图片名称以获取其id值\n",
    "    file_id = filename.split('_')[1]\n",
    "    # 如果该id在csv文件中，则将该图片复制到新的文件夹中\n",
    "    if file_id in new_id_list:\n",
    "        # 读取图像\n",
    "        image = Image.open(os.path.join(folder_path, filename))\n",
    "        data.append(get_edge(get_mask(image)))\n",
    "\n",
    "headers = ['src', 'dst']  # CSV文件头部\n",
    "\n",
    "with open('E:/Dataset/GNN_Perception/fig_out/road_grapg_pre22.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['src', 'dst'])\n",
    "    for sublist in data:\n",
    "        for row in sublist:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "edge_data = pd.read_csv('E:/Dataset/GNN_Perception/fig_out/road_grapg_pre33.csv')\n",
    "nodes = list(set(list(edge_data['src']) + list(edge_data['dst'])))\n",
    "edge_index = torch.tensor([edge_data['src'], edge_data['dst']], dtype=torch.long)\n",
    "\n",
    "data = Data(edge_index=edge_index, num_nodes=0)\n",
    "G = to_networkx(data, to_undirected=True)\n",
    "fig, ax = plt.subplots(figsize=(8,6.5))\n",
    "\n",
    "degree_centrality = nx.centrality.degree_centrality(G)  # save results in a variable to use again\n",
    "\n",
    "pos = nx.spring_layout(G, iterations=300, seed=1235, k=8)\n",
    "# pos = nx.circular_layout(G)\n",
    "\n",
    "node_color = [degree_centrality[node] for node in G.nodes()]\n",
    "\n",
    "# Get list of class names as column names\n",
    "class_names = list(model.config.id2label.values())[1:]\n",
    "# 创建字典，key 为 class 表中的元素，value 为该元素在列表中的索引\n",
    "class_dict = {class_names[i]: i for i in range(len(class_names))}\n",
    "\n",
    "# 存储节点编号和它们对应的类别索引\n",
    "labels = {}\n",
    "for node in nodes:\n",
    "    # 如果节点对应的类别不存在于 class_dict 中，则跳过该节点\n",
    "    if node >= len(class_names):\n",
    "        continue\n",
    "    # 根据 node 在 class_dict 中查找对应的 value\n",
    "    node_value = class_dict[class_names[node]]\n",
    "    labels[node] = node_value\n",
    "# 根据 labels 中的索引值获取相应的类别名称，并创建新的字典\n",
    "class_labels = {k: class_names[v] for k, v in labels.items()}\n",
    "\n",
    "nx.draw(G, node_size=80, pos=pos, with_labels=True, labels=class_labels, font_size=7, node_color=node_color, cmap=plt.cm.Purples, vmax=1.0, edge_color='gray', alpha=0.9,width=0.2)\n",
    "\n",
    "# Add legend for node color\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.Purples, norm=plt.Normalize(vmin=min(degree_centrality.values()), vmax=max(degree_centrality.values())))\n",
    "sm._A = []\n",
    "cb = plt.colorbar(sm,shrink=0.4)\n",
    "cb.set_label('Degree Centrality', fontsize=14, labelpad=10)\n",
    "\n",
    "# plt.savefig('E:/Dataset/GNN_Perception/fig_out/pre-2.svg')\n",
    "plt.show()\n",
    "\n",
    "# 计算节点的度\n",
    "degrees = dict(G.degree())\n",
    "sorted_degrees_desc = sorted(degrees.items(), key=lambda x: x[1], reverse=True)\n",
    "# 打印结果\n",
    "print(sorted_degrees_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask = predictions\n",
    "# 获取唯一的标签列表\n",
    "labels = list(np.unique(mask))\n",
    "# labels.remove(0)  # 去除背景标签0\n",
    "\n",
    "# 创建空的图\n",
    "G = nx.Graph()\n",
    "\n",
    "# 添加节点\n",
    "for label in labels:\n",
    "    nodes = np.argwhere(mask == label)  # 获取当前标签对应的像素点坐标\n",
    "    centroid = np.mean(nodes, axis=0)   # 计算节点的中心坐标\n",
    "    count = len(nodes)                  # 获取节点的像素点数目\n",
    "    total_count = mask.size             # 获取整张图的像素点数目\n",
    "    proportion = count / total_count*100   # 计算节点所占比例\n",
    "    G.add_node(label, centroid=centroid, label=class_names[label-1], proportion=proportion)  # 添加节点，并记录节点的中心坐标和节点所占比例\n",
    "\n",
    "# 添加边\n",
    "for i, (label_i, data_i) in enumerate(G.nodes(data=True)):\n",
    "    for j, (label_j, data_j) in enumerate(G.nodes(data=True)):\n",
    "        if i >= j:  # 避免重复添加边\n",
    "            continue\n",
    "        dist = np.linalg.norm(data_i['centroid'] - data_j['centroid'])  # 计算节点之间的欧式距离\n",
    "        if dist < 42:  # 如果两个节点之间的距离小于一个阈值，则添加一条边\n",
    "            G.add_edge(label_i, label_j)\n",
    "\n",
    "# 将节点的比例作为特征嵌入图中\n",
    "node_features = np.array([data['proportion'] for _, data in G.nodes(data=True)])\n",
    "nx.set_node_attributes(G, dict(enumerate(node_features)), 'proportion')\n",
    "\n",
    "# # 获取整体特征，768维度向量\n",
    "# vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "# features = vit_model(inputs.pixel_values).last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# 打印图的基本信息\n",
    "print(f'Number of nodes: {G.number_of_nodes()}')\n",
    "print(f'Number of edges: {G.number_of_edges()}')\n",
    "print(f'Nodes: {G.nodes(data=True)}')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "pos = nx.spring_layout(G, iterations=50, seed=12345)\n",
    "\n",
    "# 在绘制图形时，将特征作为参数传递给nx.draw()函数\n",
    "# nx.draw(G, node_size=50, pos={k: v['centroid'] for k, v in G.nodes(data=True)}, with_labels=True, labels=nx.get_node_attributes(G,'label'))  \n",
    "nx.draw(G, node_size=500, pos=pos, with_labels=True, labels=nx.get_node_attributes(G,'label'), \n",
    "        node_color=labels, cmap=plt.cm.Blues)  \n",
    "\n",
    "# plt.savefig('E:/Dataset/GNN_Perception/fig_out/grapg.svg',format='svg',bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
